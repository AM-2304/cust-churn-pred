{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 107399,
          "databundleVersionId": 13009703,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "MLP-KA2-22f3002773",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "84452W-SYgFz"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "mlp_term_2_2025_kaggle_assignment_2_path = kagglehub.competition_download('mlp-term-2-2025-kaggle-assignment-2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "UBQi7zDbYgF1"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-20T10:22:32.929129Z",
          "iopub.execute_input": "2025-07-20T10:22:32.929603Z",
          "iopub.status.idle": "2025-07-20T10:22:33.315632Z",
          "shell.execute_reply.started": "2025-07-20T10:22:32.929567Z",
          "shell.execute_reply": "2025-07-20T10:22:33.31477Z"
        },
        "id": "8YqYWa5YYgF2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "ARZww5hNYgF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:05:01.915095Z",
          "iopub.execute_input": "2025-07-23T07:05:01.916126Z",
          "iopub.status.idle": "2025-07-23T07:05:04.497912Z",
          "shell.execute_reply.started": "2025-07-23T07:05:01.91609Z",
          "shell.execute_reply": "2025-07-23T07:05:04.496855Z"
        },
        "id": "CMGtYQKcYgF4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "OmaLsv2HYgF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_DATA = \"/kaggle/input/mlp-term-2-2025-kaggle-assignment-2/\"\n",
        "train_df = pd.read_csv(PATH_TO_DATA + \"train.csv\")\n",
        "test_df = pd.read_csv(PATH_TO_DATA + \"test.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:05:04.499601Z",
          "iopub.execute_input": "2025-07-23T07:05:04.500201Z",
          "iopub.status.idle": "2025-07-23T07:05:04.925234Z",
          "shell.execute_reply.started": "2025-07-23T07:05:04.500164Z",
          "shell.execute_reply": "2025-07-23T07:05:04.924044Z"
        },
        "id": "iBYftxZ7YgF5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create copies of original dataframes for potential later use (e.g., submission ID)\n",
        "train_df_copy = train_df.copy(deep=True)\n",
        "test_df_copy = test_df.copy(deep=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:05:14.05531Z",
          "iopub.execute_input": "2025-07-23T07:05:14.056228Z",
          "iopub.status.idle": "2025-07-23T07:05:14.065641Z",
          "shell.execute_reply.started": "2025-07-23T07:05:14.056194Z",
          "shell.execute_reply": "2025-07-23T07:05:14.064654Z"
        },
        "id": "44ikfcjoYgF5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "a403TGCaYgF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Initial Data Inspection & Preprocessing ---\n",
        "print(\"--- Initial Data Inspection ---\")\n",
        "print(\"Train DataFrame Head:\")\n",
        "print(train_df.head(10))\n",
        "print(\"\\nTrain DataFrame Shape:\")\n",
        "print(train_df.shape)\n",
        "print(\"\\nTrain DataFrame Info:\")\n",
        "train_df.info()\n",
        "print(\"\\nTrain DataFrame Descriptive Statistics:\")\n",
        "print(train_df.describe().rename(index={\"50%\": \"median\"}))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:05:25.144792Z",
          "iopub.execute_input": "2025-07-23T07:05:25.145127Z",
          "iopub.status.idle": "2025-07-23T07:05:25.280611Z",
          "shell.execute_reply.started": "2025-07-23T07:05:25.145101Z",
          "shell.execute_reply": "2025-07-23T07:05:25.27956Z"
        },
        "id": "ukr1RCDaYgF6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop unnecessary columns"
      ],
      "metadata": {
        "id": "5Gke4tY3YgF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_remove = ['id', 'customer_id', 'last_name']\n",
        "train_df = train_df.drop(cols_to_remove, axis=1)\n",
        "test_df = test_df.drop(cols_to_remove, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:05:40.923458Z",
          "iopub.execute_input": "2025-07-23T07:05:40.923744Z",
          "iopub.status.idle": "2025-07-23T07:05:40.936437Z",
          "shell.execute_reply.started": "2025-07-23T07:05:40.923723Z",
          "shell.execute_reply": "2025-07-23T07:05:40.935333Z"
        },
        "id": "YuZAwlcNYgF6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixing Missing Data"
      ],
      "metadata": {
        "id": "XHSSDOjoYgF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nMissing rows in Train DataFrame (before imputation):')\n",
        "print(train_df.isnull().sum())\n",
        "print('\\nMissing rows ratio in Train DataFrame (before imputation):')\n",
        "print(train_df.isnull().sum() / train_df.shape[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:05:48.53027Z",
          "iopub.execute_input": "2025-07-23T07:05:48.530596Z",
          "iopub.status.idle": "2025-07-23T07:05:48.575716Z",
          "shell.execute_reply.started": "2025-07-23T07:05:48.530572Z",
          "shell.execute_reply": "2025-07-23T07:05:48.574697Z"
        },
        "id": "ikMJ6AHmYgF6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Impute missing values for numerical columns with mean and adding indicator"
      ],
      "metadata": {
        "id": "8VupRB8pYgF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "numerical_impute_cols = ['credit_score', 'acc_balance', 'prod_count']\n",
        "for col in numerical_impute_cols:\n",
        "    mean_imputer = SimpleImputer(strategy='mean', add_indicator=True)\n",
        "\n",
        "    # Fit on train and transform both train and test\n",
        "    train_df_tmp = mean_imputer.fit_transform(train_df[[col]])\n",
        "    train_df.loc[:, col] = train_df_tmp[:, 0]\n",
        "    train_df.loc[:, f'{col}_missing_indicator'] = train_df_tmp[:, 1]\n",
        "\n",
        "    test_df_tmp = mean_imputer.transform(test_df[[col]])\n",
        "    test_df.loc[:, col] = test_df_tmp[:, 0]\n",
        "    test_df.loc[:, f'{col}_missing_indicator'] = test_df_tmp[:, 1]\n",
        "\n",
        "# Impute missing values for categorical 'country' column with most frequent and add indicator\n",
        "country_imputer = SimpleImputer(strategy='most_frequent', add_indicator=True)\n",
        "train_country_tmp = country_imputer.fit_transform(train_df[['country']])\n",
        "train_df.loc[:, 'country'] = train_country_tmp[:, 0]\n",
        "train_df.loc[:, 'country_missing_indicator'] = train_country_tmp[:, 1]\n",
        "\n",
        "test_country_tmp = country_imputer.transform(test_df[['country']])\n",
        "test_df.loc[:, 'country'] = test_country_tmp[:, 0]\n",
        "test_df.loc[:, 'country_missing_indicator'] = test_country_tmp[:, 1]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:06:10.086258Z",
          "iopub.execute_input": "2025-07-23T07:06:10.086585Z",
          "iopub.status.idle": "2025-07-23T07:06:10.172477Z",
          "shell.execute_reply.started": "2025-07-23T07:06:10.08656Z",
          "shell.execute_reply": "2025-07-23T07:06:10.171645Z"
        },
        "id": "ML9OqUlOYgF7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling duplicate rows"
      ],
      "metadata": {
        "id": "xfddOi5BYgF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_dups = train_df.shape[0] - train_df.drop_duplicates().shape[0]\n",
        "print(f'\\nNumber of duplicate rows before dropping: {num_dups}')\n",
        "train_df = train_df.drop_duplicates()\n",
        "print(f'Number of duplicate rows after dropping: {train_df.shape[0] - train_df.drop_duplicates().shape[0]}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:06:20.643423Z",
          "iopub.execute_input": "2025-07-23T07:06:20.644355Z",
          "iopub.status.idle": "2025-07-23T07:06:20.841341Z",
          "shell.execute_reply.started": "2025-07-23T07:06:20.64432Z",
          "shell.execute_reply": "2025-07-23T07:06:20.840257Z"
        },
        "id": "HsHD3sUmYgF7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "w7r0p6ibYgF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Exploratory Data Analysis (EDA) ---\")\n",
        "\n",
        "# Graph 1: Histograms for numerical distributions (with KDE)\n",
        "numerical_features_for_hist = ['credit_score', 'age', 'tenure', 'acc_balance', 'prod_count', 'estimated_salary']\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "for i, col in enumerate(numerical_features_for_hist):\n",
        "    sns.histplot(data=train_df, x=col, kde=True, ax=axes[i])\n",
        "    axes[i].set_title(f'Distribution of {col}')\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Histograms of Numerical Features', y=1.02, fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Graph 2: Count Plots for categorical features\n",
        "categorical_features_for_count = ['country', 'gender', 'has_card', 'is_active', 'exit_status']\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "for i, col in enumerate(categorical_features_for_count):\n",
        "    if i < len(categorical_features_for_count): # Ensure we don't go out of bounds for axes\n",
        "        sns.countplot(data=train_df, x=col, ax=axes[i])\n",
        "        axes[i].set_title(f'Count of {col}')\n",
        "        axes[i].tick_params(axis='x', rotation=45) # Rotate labels for better readability\n",
        "    else:\n",
        "        fig.delaxes(axes[i]) # Remove unused subplots if the number of features is less than subplots\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Count Plots of Categorical Features', y=1.02, fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Graph 3: Pair Plot for selected numerical features (sampled for large datasets)\n",
        "print(\"\\nGenerating Pair Plot (may take some time for large datasets)...\")\n",
        "# Taking a smaller sample for pair plot if the dataset is very large for performance\n",
        "if train_df.shape[0] > 10000:\n",
        "    sns.pairplot(train_df.sample(n=5000, random_state=42)[['credit_score', 'age', 'acc_balance', 'exit_status']], hue='exit_status', diag_kind='kde')\n",
        "else:\n",
        "    sns.pairplot(train_df[['credit_score', 'age', 'acc_balance', 'exit_status']], hue='exit_status', diag_kind='kde')\n",
        "plt.suptitle('Pair Plot of Selected Numerical Features by Exit Status', y=1.02, fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Graph 4: Correlation Heatmap of numerical features\n",
        "print(\"\\nGenerating Correlation Heatmap...\")\n",
        "plt.figure(figsize=(10, 8))\n",
        "# Identify only the truly numerical columns (excluding boolean indicators if not desired in heatmap)\n",
        "numerical_cols_for_corr = train_df.select_dtypes(include=np.number).columns.tolist()\n",
        "# Exclude missing indicator columns from the correlation heatmap if they clutter it\n",
        "numerical_cols_for_corr = [col for col in numerical_cols_for_corr if '_missing_indicator' not in col]\n",
        "numerical_correlation_matrix = train_df[numerical_cols_for_corr].corr()\n",
        "sns.heatmap(numerical_correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Heatmap of Numerical Features')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:06:34.577743Z",
          "iopub.execute_input": "2025-07-23T07:06:34.578124Z",
          "iopub.status.idle": "2025-07-23T07:06:44.672655Z",
          "shell.execute_reply.started": "2025-07-23T07:06:34.578092Z",
          "shell.execute_reply": "2025-07-23T07:06:44.67178Z"
        },
        "id": "LR4lzLPQYgF7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outlier Detection"
      ],
      "metadata": {
        "id": "Xs_iGm8EYgF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Outlier Detection using Z-score Method ---\")\n",
        "from scipy.stats import zscore\n",
        "zscore_threshold = 3\n",
        "numerical_cols_for_outliers_check = ['credit_score', 'age', 'tenure', 'acc_balance', 'prod_count', 'estimated_salary']\n",
        "\n",
        "for col in numerical_cols_for_outliers_check:\n",
        "    # Calculate Z-scores, dropping NaNs to prevent errors if any were missed\n",
        "    col_zscores = np.abs(zscore(train_df[col].dropna()))\n",
        "    # Identify rows where the absolute Z-score exceeds the threshold\n",
        "    outliers_zscore_indices = np.where(col_zscores > zscore_threshold)[0]\n",
        "    num_outliers = len(outliers_zscore_indices)\n",
        "    percent_outliers = (num_outliers / train_df.shape[0]) * 100\n",
        "\n",
        "    print(f'\\nAnalyzing column: {col}')\n",
        "    print(f'Number of outliers (Z-score > {zscore_threshold}): {num_outliers}')\n",
        "    print(f'Percentage of outliers: {percent_outliers:.2f}%')\n",
        "    print('Sample of outlier values:', train_df[col].iloc[outliers_zscore_indices].head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:08:52.281387Z",
          "iopub.execute_input": "2025-07-23T07:08:52.282231Z",
          "iopub.status.idle": "2025-07-23T07:08:52.317241Z",
          "shell.execute_reply.started": "2025-07-23T07:08:52.282195Z",
          "shell.execute_reply": "2025-07-23T07:08:52.31592Z"
        },
        "id": "wgvwpd0IYgF7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Pipeline Setup for Modeling"
      ],
      "metadata": {
        "id": "RwLY5q2FYgF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import tempfile # For caching pipelines\n",
        "\n",
        "# Create a temporary directory for caching\n",
        "cachedir1 = tempfile.mkdtemp()\n",
        "\n",
        "# Define column types for preprocessing\n",
        "numerical_cols = ['credit_score', 'age', 'tenure', 'acc_balance', 'prod_count', 'estimated_salary', 'has_card', 'is_active']\n",
        "# Dynamically get missing indicator columns\n",
        "missing_indicator_cols = [col for col in train_df.columns if '_missing_indicator' in col]\n",
        "categorical_cols = ['country', 'gender']\n",
        "\n",
        "# Numerical transformation pipeline\n",
        "numeric_transformer = StandardScaler()\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('scaler', numeric_transformer)\n",
        "])\n",
        "\n",
        "# Categorical transformation pipeline\n",
        "one_hot_categorical_transformer = OneHotEncoder(handle_unknown='ignore', drop='if_binary')\n",
        "\n",
        "# Combine all transformers using ColumnTransformer\n",
        "preprocessor_one_hot = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_pipeline, numerical_cols),\n",
        "        ('cat', one_hot_categorical_transformer, categorical_cols),\n",
        "        ('missing_indicator', 'passthrough', missing_indicator_cols) # Pass through missing indicators\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Add VarianceThreshold for feature selection (removes zero-variance features)\n",
        "var_thresh_preprocessor_one_hot = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_one_hot),\n",
        "    ('var_thresh', VarianceThreshold(threshold=0.0))\n",
        "],\n",
        "    memory=cachedir1 # Cache the pipeline steps\n",
        ")\n",
        "\n",
        "# Map preprocessors to model types (all use the same preprocessor here)\n",
        "preprocessor_pipeline_map = {\n",
        "    'logistic_regression': var_thresh_preprocessor_one_hot,\n",
        "    'perceptron': var_thresh_preprocessor_one_hot,\n",
        "    'random_forest_classifier': var_thresh_preprocessor_one_hot,\n",
        "    'gradient_boosting_classifier': var_thresh_preprocessor_one_hot,\n",
        "    'ada_boost_classifier': var_thresh_preprocessor_one_hot,\n",
        "    'decision_tree_classifier': var_thresh_preprocessor_one_hot,\n",
        "    'knn_classifier': var_thresh_preprocessor_one_hot,\n",
        "    'mlp_classifier': var_thresh_preprocessor_one_hot # Added MLP to ensure 7 models\n",
        "}\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:08:55.790902Z",
          "iopub.execute_input": "2025-07-23T07:08:55.791304Z",
          "iopub.status.idle": "2025-07-23T07:08:55.856393Z",
          "shell.execute_reply.started": "2025-07-23T07:08:55.791275Z",
          "shell.execute_reply": "2025-07-23T07:08:55.855538Z"
        },
        "id": "8EpnC4eKYgF7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define X_train, y_train, X_test\n",
        "X_train = train_df.drop(columns='exit_status')\n",
        "y_train = train_df['exit_status']\n",
        "X_test = test_df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:09:17.708894Z",
          "iopub.execute_input": "2025-07-23T07:09:17.709274Z",
          "iopub.status.idle": "2025-07-23T07:09:17.71881Z",
          "shell.execute_reply.started": "2025-07-23T07:09:17.709248Z",
          "shell.execute_reply": "2025-07-23T07:09:17.718023Z"
        },
        "id": "entuBCW8YgF7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the preprocessor to training data and inspect features\n",
        "var_thresh_preprocessor_one_hot.fit(X_train)\n",
        "processed_feature_names = var_thresh_preprocessor_one_hot.get_feature_names_out()\n",
        "print('\\nNo. of features after preprocessing:', len(processed_feature_names))\n",
        "print('Features after preprocessing:', processed_feature_names) # Uncomment to see feature names"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:09:32.544065Z",
          "iopub.execute_input": "2025-07-23T07:09:32.544996Z",
          "iopub.status.idle": "2025-07-23T07:09:33.503023Z",
          "shell.execute_reply.started": "2025-07-23T07:09:32.544929Z",
          "shell.execute_reply": "2025-07-23T07:09:33.501678Z"
        },
        "id": "OQG59Ua5YgF7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definitions"
      ],
      "metadata": {
        "id": "sN3LPgglYgF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "model_estimators = {\n",
        "    'logistic_regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'perceptron': Perceptron(random_state=42),\n",
        "    'random_forest_classifier': RandomForestClassifier(random_state=42),\n",
        "    'gradient_boosting_classifier': GradientBoostingClassifier(random_state=42),\n",
        "    'ada_boost_classifier': AdaBoostClassifier(random_state=42),\n",
        "    'decision_tree_classifier': DecisionTreeClassifier(random_state=42),\n",
        "    'knn_classifier': KNeighborsClassifier(n_neighbors=3),\n",
        "    'mlp_classifier': MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', alpha=0.0001, learning_rate='adaptive', max_iter=200, random_state=42)\n",
        "}\n",
        "\n",
        "# Create full pipelines for each model\n",
        "modeling_pipelines = {\n",
        "    m_name:\n",
        "    Pipeline(steps=[\n",
        "        ('pre', preprocessor_pipeline_map[m_name]),\n",
        "        ('model', m_head)\n",
        "    ])\n",
        "    for m_name, m_head in model_estimators.items()\n",
        "}\n",
        "print(\"\\nModels initialized for evaluation:\")\n",
        "print(list(modeling_pipelines.keys()))\n",
        "\n",
        "print(\"\\nTarget variable (exit_status) distribution in training data:\")\n",
        "print(train_df['exit_status'].value_counts())\n",
        "\n",
        "\n",
        "# This function is used to handle imbalanced datasets by oversampling the minority class.\n",
        "def data_oversampler(X, y, group_rules):\n",
        "    all_oversampled_indices = []\n",
        "    for rule_func, multiplier in group_rules:\n",
        "        group_subset_index = list(y[rule_func(y)].index)\n",
        "        num_group_members = len(group_subset_index)\n",
        "        # Randomly sample with replacement to oversample\n",
        "        group_sampled_indices = np.random.choice(group_subset_index, size=int(num_group_members * multiplier), replace=True)\n",
        "        all_oversampled_indices.extend(group_sampled_indices)\n",
        "\n",
        "    combined_indices = list(y.index) + all_oversampled_indices\n",
        "    np.random.shuffle(combined_indices) # Shuffle to mix original and oversampled data\n",
        "\n",
        "    X_oversampled = X.loc[combined_indices].reset_index(drop=True)\n",
        "    y_oversampled = y.loc[combined_indices].reset_index(drop=True)\n",
        "    return X_oversampled, y_oversampled"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:10:18.904255Z",
          "iopub.execute_input": "2025-07-23T07:10:18.904617Z",
          "iopub.status.idle": "2025-07-23T07:10:18.941069Z",
          "shell.execute_reply.started": "2025-07-23T07:10:18.904593Z",
          "shell.execute_reply": "2025-07-23T07:10:18.940111Z"
        },
        "id": "CyjOdPQbYgF8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold Cross-Validation and Initial Model Evaluation"
      ],
      "metadata": {
        "id": "NqqzqXsSYgF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.base import clone\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42) # 5-fold cross-validation\n",
        "\n",
        "model_performance_scores = {\n",
        "    'model_name': [],\n",
        "    'f1_score': []\n",
        "}\n",
        "\n",
        "print(\"\\n--- Starting K-Fold Cross-Validation for Initial Model Evaluation ---\")\n",
        "for current_model_name, current_model_pipeline in modeling_pipelines.items():\n",
        "\n",
        "    fold_f1_scores = []\n",
        "    fitted_fold_models = []\n",
        "\n",
        "    for fold, (train_split_idx, val_split_idx) in enumerate(kf.split(X_train)):\n",
        "        X_training, X_validation = X_train.iloc[train_split_idx], X_train.iloc[val_split_idx]\n",
        "        y_training, y_validation = y_train.iloc[train_split_idx], y_train.iloc[val_split_idx]\n",
        "\n",
        "        model_instance = clone(current_model_pipeline) # Clone model for each fold\n",
        "\n",
        "        # Apply oversampling to the training data of the current fold\n",
        "        # Here, we oversample the positive class (exit_status == 1) by 1.4 times\n",
        "        oversampling_rules = [(lambda x: x == 1, 1.4)]\n",
        "        X_training_sampled, y_training_sampled = data_oversampler(X_training, y_training, oversampling_rules)\n",
        "\n",
        "        model_instance.fit(X_training_sampled, y_training_sampled) # Fit the model\n",
        "        y_predicted = model_instance.predict(X_validation) # Make predictions on validation set\n",
        "        f1 = f1_score(y_validation, y_predicted) # Calculate F1 score\n",
        "\n",
        "        fold_f1_scores.append(f1)\n",
        "        fitted_fold_models.append(model_instance)\n",
        "\n",
        "    # Store the best performing model from the current model type's folds\n",
        "    best_fold_f1_score = np.max(fold_f1_scores)\n",
        "    index_of_best_fold = np.argmax(fold_f1_scores)\n",
        "    best_fitted_model_for_type = fitted_fold_models[index_of_best_fold]\n",
        "\n",
        "    # Update the modeling_pipelines dictionary with the best fitted model for this type\n",
        "    modeling_pipelines[current_model_name] = best_fitted_model_for_type\n",
        "\n",
        "    print(f'Model: {current_model_name} | F1 Scores across folds: {fold_f1_scores}, | Avg F1: {np.mean(fold_f1_scores):.4f} +/- {np.std(fold_f1_scores):.4f}')\n",
        "\n",
        "    model_performance_scores['model_name'].append(current_model_name)\n",
        "    model_performance_scores['f1_score'].append(best_fold_f1_score)\n",
        "\n",
        "print(\"\\n--- Initial Model Performance Summary (before Hyperparameter Tuning) ---\")\n",
        "initial_perf_df = pd.DataFrame(model_performance_scores).sort_values(by='f1_score', ascending=False)\n",
        "print(initial_perf_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:10:37.09127Z",
          "iopub.execute_input": "2025-07-23T07:10:37.091612Z",
          "iopub.status.idle": "2025-07-23T07:24:10.723543Z",
          "shell.execute_reply.started": "2025-07-23T07:10:37.09159Z",
          "shell.execute_reply": "2025-07-23T07:24:10.722486Z"
        },
        "id": "rXu6ZC2dYgF8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning for Top 3 Best Models"
      ],
      "metadata": {
        "id": "9Y4TFTixYgF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Get the names of the top 3 models for Hyperparameter Tuning\n",
        "top_3_models_for_hpt = initial_perf_df['model_name'].head(3).tolist()\n",
        "print(f\"\\n--- Starting Hyperparameter Tuning for Top 3 Models: {top_3_models_for_hpt} ---\")\n",
        "\n",
        "# Define hyperparameter grids for tuning\n",
        "# Gradient Boosting Classifier HPT\n",
        "if 'gradient_boosting_classifier' in top_3_models_for_hpt:\n",
        "    gb_hyperparam_grid = {\n",
        "        'model__n_estimators': np.linspace(100, 300, 10, dtype=int),\n",
        "        'model__learning_rate': np.logspace(-2, -0.5, 10),\n",
        "        'model__max_depth': np.arange(3, 30),\n",
        "        'model__min_samples_split': np.linspace(2, 20, 10, dtype=int),\n",
        "        'model__min_samples_leaf': np.linspace(1, 20, 10, dtype=int),\n",
        "        'model__subsample': np.linspace(0.5, 1.0, 6),\n",
        "        'model__loss': ['log_loss', 'exponential']\n",
        "    }\n",
        "\n",
        "    print(\"\\nPerforming Randomized Search for Gradient Boosting Classifier...\")\n",
        "    gb_rand_search = RandomizedSearchCV(clone(modeling_pipelines['gradient_boosting_classifier']), gb_hyperparam_grid, cv=5, scoring='f1', n_jobs=-1, random_state=42, verbose=1)\n",
        "    gb_rand_search.fit(X_train, y_train) # Fit on full training data\n",
        "    print('Gradient Boosting best score/params:', gb_rand_search.best_score_, gb_rand_search.best_params_)\n",
        "    model_performance_scores['model_name'].append('gradient_boosting_classifier_tuned')\n",
        "    modeling_pipelines['gradient_boosting_classifier_tuned'] = gb_rand_search # Store the best estimator from RandomizedSearchCV\n",
        "    model_performance_scores['f1_score'].append(gb_rand_search.best_score_)\n",
        "\n",
        "# AdaBoost Classifier HPT\n",
        "if 'ada_boost_classifier' in top_3_models_for_hpt:\n",
        "    ada_hyperparam_grid = {\n",
        "        'model__n_estimators': np.linspace(50, 500, 10, dtype=int),\n",
        "        'model__learning_rate': np.logspace(-2, 0, 20),\n",
        "        'model__algorithm': ['SAMME', 'SAMME.R']\n",
        "    }\n",
        "\n",
        "    print(\"\\nPerforming Randomized Search for AdaBoost Classifier...\")\n",
        "    ada_rand_search = RandomizedSearchCV(clone(modeling_pipelines['ada_boost_classifier']), ada_hyperparam_grid, cv=5, scoring='f1', n_jobs=-1, random_state=42, verbose=1)\n",
        "    ada_rand_search.fit(X_train, y_train)\n",
        "    print('AdaBoost best score/params:', ada_rand_search.best_score_, ada_rand_search.best_params_)\n",
        "    model_performance_scores['model_name'].append('ada_boost_classifier_tuned')\n",
        "    modeling_pipelines['ada_boost_classifier_tuned'] = ada_rand_search\n",
        "    model_performance_scores['f1_score'].append(ada_rand_search.best_score_)\n",
        "\n",
        "# Random Forest Classifier HPT\n",
        "if 'random_forest_classifier' in top_3_models_for_hpt:\n",
        "    rf_hyperparam_grid = {\n",
        "        'model__min_samples_split': np.arange(2, 20),\n",
        "        'model__min_samples_leaf': np.arange(1, 10),\n",
        "        'model__n_estimators': np.linspace(100, 600, 10, dtype=int),\n",
        "        'model__max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
        "    }\n",
        "\n",
        "    print(\"\\nPerforming Randomized Search for Random Forest Classifier...\")\n",
        "    rf_rand_search = RandomizedSearchCV(clone(modeling_pipelines['random_forest_classifier']), rf_hyperparam_grid, cv=5, scoring='f1', n_jobs=-1, random_state=42, verbose=1)\n",
        "    rf_rand_search.fit(X_train, y_train)\n",
        "    print('Random Forest best score/params:', rf_rand_search.best_score_, rf_rand_search.best_params_)\n",
        "    model_performance_scores['model_name'].append('random_forest_classifier_tuned')\n",
        "    modeling_pipelines['random_forest_classifier_tuned'] = rf_rand_search\n",
        "    model_performance_scores['f1_score'].append(rf_rand_search.best_score_)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T07:24:10.725055Z",
          "iopub.execute_input": "2025-07-23T07:24:10.72536Z",
          "iopub.status.idle": "2025-07-23T08:21:46.708557Z",
          "shell.execute_reply.started": "2025-07-23T07:24:10.725338Z",
          "shell.execute_reply": "2025-07-23T08:21:46.707524Z"
        },
        "id": "Stb5CKuZYgF8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Model Performance Summary"
      ],
      "metadata": {
        "id": "052ztPrFYgF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_performance_df = pd.DataFrame(model_performance_scores)\n",
        "final_model_performance_df = final_model_performance_df.sort_values(by=['f1_score'], axis=0, ascending=False)\n",
        "print(\"\\n--- Final Model Performance Summary (including tuned models) ---\")\n",
        "print(final_model_performance_df)\n",
        "\n",
        "best_model_for_submission_name = final_model_performance_df.iloc[0, 0]\n",
        "print(f'\\nBest performing Model selected for submission: {best_model_for_submission_name}')\n",
        "best_model_for_submission = modeling_pipelines[best_model_for_submission_name]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T08:21:46.709717Z",
          "iopub.execute_input": "2025-07-23T08:21:46.710114Z",
          "iopub.status.idle": "2025-07-23T08:21:46.720668Z",
          "shell.execute_reply.started": "2025-07-23T08:21:46.710078Z",
          "shell.execute_reply": "2025-07-23T08:21:46.719387Z"
        },
        "id": "TdxWam-5YgF8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Predictions and Creating Submission File"
      ],
      "metadata": {
        "id": "-FT7VdjXYgF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Generating Predictions for Submission ---\")\n",
        "# Predict on the test data using the best model\n",
        "y_predictions_on_test = best_model_for_submission.predict(X_test)\n",
        "\n",
        "# Create submission DataFrame, preserving the original 'id' from test_df_copy\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_df_copy['id'],\n",
        "    'exit_status': y_predictions_on_test\n",
        "})\n",
        "\n",
        "print(\"\\nSubmission DataFrame Head:\")\n",
        "print(submission_df.head())\n",
        "\n",
        "# Save the submission file\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"\\nSubmission file 'submission.csv' created successfully.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-23T08:21:46.722062Z",
          "iopub.execute_input": "2025-07-23T08:21:46.722308Z",
          "iopub.status.idle": "2025-07-23T08:21:46.922889Z",
          "shell.execute_reply.started": "2025-07-23T08:21:46.72229Z",
          "shell.execute_reply": "2025-07-23T08:21:46.921921Z"
        },
        "id": "6PSmwqUqYgF9"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}